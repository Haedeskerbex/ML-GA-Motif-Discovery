{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 23:25:30.623195: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-03 23:25:30.628952: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-03 23:25:30.642256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741024530.663743   20314 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741024530.670031   20314 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-03 23:25:30.694945: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "from Bio import SeqIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned FASTA saved as ../data/ACE2/clean_reduced_ACE2.fasta\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/ACE2/reduced_ACE2.fasta\"\n",
    "output_file = \"../data/ACE2/clean_reduced_ACE2.fasta\"\n",
    "\n",
    "with open(output_file, \"w\") as out_f:\n",
    "    for record in SeqIO.parse(input_file, \"fasta\"):\n",
    "        record.seq = record.seq.replace(\"-\",\"\")  # Remove gaps\n",
    "        SeqIO.write(record, out_f, \"fasta\")\n",
    "\n",
    "print(\"Cleaned FASTA saved as\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted features saved to onehot_features.pkl | Shape: (528, 7093, 20)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Input and output paths\n",
    "INPUT_FASTA = \"../data/ACE2/clean_reduced_ACE2.fasta\"\n",
    "OUTPUT_FEATURES = \"onehot_features.pkl\"\n",
    "\n",
    "# Define amino acid vocabulary\n",
    "AMINO_ACIDS = \"ACDEFGHIKLMNPQRSTVWY\"  # 20 standard amino acids\n",
    "AA_TO_INDEX = {aa: i for i, aa in enumerate(AMINO_ACIDS)}\n",
    "\n",
    "# Function to one-hot encode a sequence\n",
    "def one_hot_encode(seq, max_length):\n",
    "    encoded = np.zeros((max_length, len(AMINO_ACIDS)), dtype=np.float32)\n",
    "    for i, aa in enumerate(seq):\n",
    "        if aa in AA_TO_INDEX:\n",
    "            encoded[i, AA_TO_INDEX[aa]] = 1\n",
    "    return encoded\n",
    "\n",
    "# Main feature extraction function\n",
    "def extract_features(input_fasta, output_file):\n",
    "    sequences = [str(record.seq) for record in SeqIO.parse(input_fasta, \"fasta\")]\n",
    "    max_length = max(len(seq) for seq in sequences)  # Pad to longest sequence\n",
    "\n",
    "    features = np.array([one_hot_encode(seq, max_length) for seq in sequences])\n",
    "\n",
    "    # Save features\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(features, f)\n",
    "\n",
    "    print(f\"✅ Extracted features saved to {output_file} | Shape: {features.shape}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(INPUT_FASTA):\n",
    "        print(f\"❌ ERROR: {INPUT_FASTA} not found!\")\n",
    "    else:\n",
    "        extract_features(INPUT_FASTA, OUTPUT_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Load extracted features\n",
    "with open(\"onehot_features.pkl\", \"rb\") as f:\n",
    "    X = pickle.load(f)  # Shape: (528, 7093, 20)\n",
    "\n",
    "# Dummy labels (Replace with real labels if available)\n",
    "y = np.random.randint(0, 2, size=(X.shape[0],))  # Binary labels (0 or 1)\n",
    "\n",
    "# Define CNN Model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\", input_shape=(X.shape[1], X.shape[2])),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(filters=128, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")  # Binary classification output\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "model.fit(X, y, epochs=10, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# Save model\n",
    "model.save(\"ACE2_mutation_predictor.h5\")\n",
    "print(\"✅ Model training complete. Saved as ACE2_mutation_predictor.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
